{
  "lr": 0.1,
  "optimizer": "adam",
  "max_epochs": 50,
  "dropout": 0.1,
  "early_stopping": true,
  "early_stopping_patience": 6,
  "early_stopping_delta": 0.05,
  "lr_scheduler": "warmup_cosine_annealing",
  "log_losses": "both",
  "lr_scheduler_kwargs": {
    "base_lr": 0.001,
    "warmup_epochs": 2,
    "num_epochs": 20
  }
}